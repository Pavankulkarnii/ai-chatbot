# AI Chatbot v2.0 - With Next-Word Prediction

A ChatGPT-like chatbot with intelligent next-word predictions, powered by GPT-2 and optimized for Apple Silicon (M4).

## âœ¨ Features

- ðŸ’¬ **Smart Conversations**: Powered by GPT-2 medium model
- ðŸ”® **Next-Word Prediction**: Real-time autocomplete suggestions
- âš¡ **MPS Accelerated**: Uses Apple Silicon GPU for faster inference
- ðŸ’¾ **Response Caching**: Caches responses for improved performance
- ðŸ”Œ **WebSocket Support**: Real-time chat with typing indicators
- ðŸŽ¨ **Modern UI**: Clean, responsive interface with dark theme

## ðŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/Pavankulkarnii/ai-chatbot.git
cd ai-chatbot
```

### 2. Install Dependencies
```bash
# Create virtual environment
python3 -m venv venv

# Activate it (macOS/Linux)
source venv/bin/activate

# Install packages
pip install -r backend/requirements.txt
```

### 3. Run Backend Server
```bash
cd backend
python main.py
```

Wait for the message: `Model will be loaded on first request (lazy loading)`

The model will automatically load when you send your first message.

### 4. Run Frontend (New Terminal)
```bash
cd frontend
python3 -m http.server 3000
```

### 5. Open Browser

Go to: **http://localhost:3000**

## ðŸŽ¯ Usage

### Chat
- Type your message in the input box
- Press Enter or click Send
- Wait for AI response

### Next-Word Prediction
- Start typing (minimum 3 characters)
- Autocomplete suggestions appear above input
- Click any suggestion to insert it
- Predictions show probability scores

### Controls
- **Reset**: Clear conversation history
- **Clear Cache**: Clear response cache

## ðŸ“¡ API Endpoints

### Chat
```bash
POST /api/chat
Body: {"message": "Hello", "temperature": 0.7, "max_length": 1000}
```

### Next-Word Prediction
```bash
POST /api/predict
Body: {"text": "Hello how are", "num_predictions": 3, "temperature": 0.8}
```

### Reset Conversation
```bash
POST /api/reset
```

### Clear Cache
```bash
POST /api/clear-cache
```

### Model Info
```bash
GET /api/info
```

### WebSocket
```
ws://localhost:8000/ws/chat
```

## ðŸ”§ Configuration

Edit `backend/chat_model.py` to change model:
```python
# Options:
# - "gpt2-medium" (355M params) - Default, good balance
# - "gpt2-large" (774M params) - Better quality
# - "meta-llama/Llama-3.2-1B-Instruct" - Best quality
```

## ðŸ“Š Performance

- **First request**: 20-30 seconds (model loading)
- **Subsequent requests**: 1-3 seconds per response
- **Next-word prediction**: <500ms
- **Memory usage**: ~2-3GB RAM with gpt2-medium
- **Device**: Automatically uses MPS (Apple Silicon GPU)

## ðŸ› Troubleshooting

### Backend won't start
```bash
# Check Python version
python --version  # Should be 3.8+

# Reinstall dependencies
pip install --upgrade -r backend/requirements.txt
```

### Model loading fails
```bash
# Clear model cache and retry
rm -rf backend/models/
```

### MPS not available
```bash
# Check PyTorch MPS support
python -c "import torch; print(torch.backends.mps.is_available())"
```

### CORS errors
The backend allows all origins (`allow_origins=["*"]`). 
For production, update `backend/main.py`:
```python
allow_origins=["http://localhost:3000"]
```

## ðŸ“ Project Structure
```
ai-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â”œâ”€â”€ chat_model.py        # Model handler (NEW)
â”‚   â””â”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html           # UI (UPDATED)
â”‚   â””â”€â”€ app.js               # Logic (UPDATED)
â”œâ”€â”€ .gitignore               # Ignore large files
â””â”€â”€ README.md                # This file
```

## ðŸ”„ Updates in v2.0

- âœ… Added next-word prediction endpoint
- âœ… Upgraded to GPT-2 for better responses
- âœ… Implemented response caching
- âœ… Lazy model loading for faster startup
- âœ… Shared model instance across endpoints
- âœ… Live autocomplete in frontend
- âœ… Probability scores for predictions
- âœ… MPS (Apple Silicon) optimization

## ðŸ“ License

MIT License

## ðŸ¤ Contributing

Pull requests welcome! For major changes, please open an issue first.

## ðŸ“§ Contact

GitHub: [@Pavankulkarnii](https://github.com/Pavankulkarnii)
